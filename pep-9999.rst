PEP: 9999
Title: Literal types
Author: Some subset of the mypy team
Status: Draft
Type: Standards Track
Python-Version: 3.8
Content-Type: text/x-rst
Created: 19-Nov-2018
Post-History: 19-Nov-2018

Abstract
========

This PEP proposes to extend the PEP 484 typing ecosystem by adding
*Literal types*, which indicate that some expression has literally a
specific value. For example, the following function will accept only
expressions that literally have the value "4"::

    from typing import Literal

    def accepts_only_four(x: Literal[4]) -> None:
        pass

    accepts_only_four(4)  # Type checker accepts
    accepts_only_four(8)  # Type checker rejects

**Note:** This PEP should be considered to be very early draft: we plan
on refining it as we add corresponding proof-of-concept implementation
to mypy.

Motivation and Rationale
========================

Python has many APIs that return different types depending on the exact
value of some argument provided. For example:

-  ``open(filename, mode)`` can return an ``IO[bytes]`` or ``IO[Text]``
   depending on whether the second argument is something like “r” or
   “rb”
-  ``subprocess.check_output(…)`` can also return bytes or text
   depending on whether the ``universal_newlines`` keyword argument is
   set to ``True`` or not.

This pattern is also fairly common in many popular 3rd party libraries.
For example, here are just two examples from pandas and numpy respectively:

-  ``pandas.concat(...)`` will return either ``Series`` or
   ``DataFrame`` depending on whether the ``axis`` argument is set to
   0 or 1.

-  ``numpy.unique`` will return either a single array or a tuple containing
   anywhere from two to four arrays depending on three boolean flag values.

The typing issue tracker contains some
`additional examples and discussion <typing-discussion_>`_.

There is currently no way of expressing the type signatures of these
functions: PEP 484 does not include any mechanism for writing signatures
where the return type varies depending on the value passed in. 
Note that this problem does not go away even if we redesign these APIs to
accept enums instead of string or int literals: the expressions ``MyEnum.FOO``
and ``MyEnum.BAR`` are both considered to be of type ``MyEnum``.)

Currently, type checkers work around this limitation by adding ad-hoc
extensions for important builtins and standard library functions. For
example mypy comes bundled with a plugin that attempts to infer more
precise types for ``open(…)``. While this approach works for standard
library functions, it’s unsustainable in general: it’s not reasonable to
expect 3rd party library authors to maintain plugins for N different
type checkers, for example.

It is, of course, debatable whether these APIs are actually good design:
type checking would be simplified if we we could split functions like
``open(...)`` into two. However, this question is to a large degree
moot: there already exist many widely-used libraries and functions that
vary their behavior based on the provided values. Therefore, we believe that
it is important for the PEP 484 type ecosystem to be updated to match.

We propose to add *Literal types* to address exactly this gap.

Specification
=============

Core Semantics
--------------

This section of the doc outlines the baseline behavior of literal types.

Core behavior
'''''''''''''

Literal types let us indicate that a variable has a specific and
concrete value. For example, if we define some variable ``foo`` to have
type ``Literal[3]``, we are declaring that ``foo`` must be exactly equal
to ``3`` and no other value.

Given some value ``V`` that is a member of type ``T``, the type
``Literal[V]`` shall be treated as a subtype of ``T``. For example,
``Literal[3]`` is a subtype of ``int``.

All of the methods of the parent type will be directly inherited by the
literal type. This means that if we have some variable ``foo`` of type
``Literal[3]``, it’s safe to do things like ``foo + 5`` since ``foo``
ultimately inherits int’s ``__add__`` method. The resulting type of
``foo + 5`` will be ``int``.

This “inheriting” behavior is identical to how we handle NewTypes.

Equivalence of two Literals
'''''''''''''''''''''''''''

Suppose we have two literal types ``Literal[A]`` and ``Literal[B]``.
Both types are considered equivalent when both of the following
conditions are true:

1. ``type(A) == type(B)``
2. ``A == B``

So for example, ``Literal[20]`` and ``Literal[0x14]`` would be
equivalent. However, ``Literal[0]`` and ``Literal[False]`` would *not*
be considered equivalent despite the fact that ``0 == False`` evaluates
to ‘true’ at runtime: ``0`` has type ``int`` and ``False`` has type
``bool``.

Shortening unions of literals
'''''''''''''''''''''''''''''

Literals may be parameterized with one or more values. When a Literal is
parameterized with more then one value, it is treated as being exactly
equivalent to the union of those values. That is,
``Literal[V1, V2, V3]`` is equivalent to
``Union[Literal[V1], Literal[V2], Literal[V3]]``.

This shortcut can make writing signatures for functions that can accept
many different literals more ergonomic — for example, functions like
``open(…)``::

   # Note: this is an over-simplification of the true type signature.
   _PathType = Union[str, bytes, int]

   @overload
   def open(path: _PathType, 
            mode: Literal["r", "w", "a", "x", "r+", "w+", "a+", "x+"],
            ) -> IO[Text]: ...
   @overload
   def open(path: _PathType, 
            mode: Literal["rb", "wb", "ab", "xb", "r+b", "w+b", "a+b", "x+b"],
            ) -> IO[bytes]: ...

   # Fallback overload for when the user isn't using literal types
   @overload
   def open(path: _PathType, mode: str) -> IO[Any]: ...

**Note:** Literals **must** be parameterized with at least one type.
Types like ``Literal[]`` or ``Literal`` should be rejected by the type
checker.

Legal and illegal parameterizations
-----------------------------------

This section of the doc describes exactly which values may or may not
parameterize a ``Literal[…]`` type.

Legal parameters for ``Literal`` at type check time
'''''''''''''''''''''''''''''''''''''''''''''''''''

``Literal`` may be parameterized with literal ints, native strings,
bools, Enum values, and ``None``. So for example, all of the following
would be legal::

   Literal[26]
   Literal[0x1A]  # Exactly equivalent to Literal[26]
   Literal["hello world"]
   Literal[True]
   Literal[Color.RED]  # Assuming Color is some enum
   Literal[None]

**Note:** The type ``Literal[None]`` is redundant in that the type
``None`` has only a single inhabitant. We nevertheless allow this 
for consistency and ease-of-use. For example, when writing a literal
with multiple parameters, it might look a little cleaner to do
``Literal[1, 2, 3, None]`` instead of ``Optional[Literal[1, 2, 3]]``.

Illegal parameters for ``Literal`` at type check time
'''''''''''''''''''''''''''''''''''''''''''''''''''''

The following parameters are provisionally disallowed, mostly for
simplicity. We can consider adding these to the above list on a
case-by-case basis based on demand.

-  Explicit byte strings: e.g. ``Literal[b'foo']``

-  Explicit unicode strings: e.g. ``Literal[u'foo']``

-  Floats: e.g. ``Literal[3.14]`` Note: if we do decide to allow
   floats, we should likely disallow literal infinity and literal NaN.

-  Any: e.g. ``Literal[Any]`` Note: the semantics of what exactly
   ``Literal[Any]`` means would need to be clarified first.

-  Literal types themselves (or aliases to literal types) e.g. if we
   create a type alias ``BasicIds = Literal[1, 2, 3]``, then perhaps
   ``Literal[100, BasicIds]`` should be treated as being equivalent to
   ``Literal[100, 1, 2, 3]``.

The following parameters are intentionally disallowed by design. We will
most likely never add these parameters at a future date, unless somebody
is able to come up with an extremely compelling argument to the
contrary.

-  Arbitrary expressions like ``Literal[3 + 4]`` or
   ``Literal["foo".replace("o", "b")]``. Literal types are meant to be a simple and
   minimal extension to the PEP 484 typing ecosystem, and requiring type
   checkers to interpret potentially expressions inside types adds too
   much complexity to this proposal. Also see the
   `Rejected or out-of-scope ideas`_ section of this doc below.

-  Complex numbers like ``Literal[4 + 3j]``, ``Literal[-4 + 2j]``, and
   ``Literal[5j]``. Types like ``Literal[4 + 3j]`` would violate the
   previous rule; it would then be consistent to also not allow types
   like ``Literal[4j]``.

-  Tuples containing valid literal types — so ``Literal[(1, "foo", "bar")]``
   would be disallowed. The user could always express this type as
   ``Tuple[Literal[1], Literal["foo"], Literal["bar"]]`` instead. Also,
   tuples are likely to be confused with the ``Literal[1, 2, 3]``
   shortcut.

-  Mutable literal data structures like dict literals, list literals, or
   set literals: literals are always implicitly final and immutable. So,
   ``Literal[{"a": "b", "c": "d"}]`` would be disallowed.

-  Any other types. So, things like ``Literal[MyTypedDict]``, or
   ``Literal[some_object_instance]`` would be disallowed.
   This includes typevars: if ``T`` is a typevar, types like
   ``Literal[T]`` is not allowed. Typevars can vary over only types, not
   over values.

Parameters at runtime
'''''''''''''''''''''

The set of allowable parameters for ``Literal[...]`` is currently
deliberately very strict and limited. However, we may want to extend the
set of allowable parameters in the future or extend the behavior of
``Literal`` in other ways.

To help us retain this flexibility, the actual implementation of
``typing.Literal`` shall perform *no* checks on any parameters provided
at runtime. For example::

   def my_function(x: Literal[1 + 2]) -> None:
       pass
       
   x: Literal = 3
   y: Literal[my_function] = my_funcion

The type checker should reject this program: all three uses of
``Literal`` are *invalid* according to this spec. However, Python itself
should execute this program with no errors.

Literals, enums, and forward references
'''''''''''''''''''''''''''''''''''''''

One potential point of ambiguity is between literal strings and forward
references to literal enum members. For example, suppose we have the
type ``Literal["Color.RED"]``. Does this literal type
contain a string literal, or a forward reference to some ``Color.RED``
enum member?

In cases like these, we will always assume the user meant to construct a
literal string. If the user wants a forward reference, they must wrap
the entire literal type as a string -- e.g. ``Literal[Color.RED]``.

The other alternative is to just not allow literal enums and avoid the
ambiguity altogether, but it seems a shame to give them up.

Literals, enums, and Any
''''''''''''''''''''''''

Another point of ambiguity is when the user attempts to use some
expression that is meant to be an enum, but is actually of type ‘Any’.
This can happen when the user, for example, attempts to import an enum
with no type stubs::

   from typing import Literal
   from lib_with_no_types import SomeEnum  # SomeEnum has type 'Any'!

   # Signature is equivalent to `func(x: Literal[Any]) -> None`
   # due to the bad import
   def func(x: Literal[SomeEnum.FOO]) -> None: pass

In this case, should a type checker report an error with ``func``? On
one hand, it makes sense to allow this: it’s usually safe to substitute
``Any`` anywhere where a type is expected, and we don’t normally report
errors if a function attempts to use a type that was inferred to be
equivalent to ``Any``.

On the other, ``Literal[…]`` expects a value, not a type, and ``Any`` is
*not* meant to represent a placeholder for any arbitrary *value*. The
semantics of what ``Literal[Any]`` means is also somewhat unclear — so,
we’ve tentatively decided to disallow ``Literal[Any]`` for now.

So in this example, the type checker should reject the signature of
``func`` for using a bad ``Literal`` type.

This decision is provisional and may be changed at a future date.

Inferring types for literal expressions
---------------------------------------

This section of the doc describes how to infer the correct type for
literal expressions — e.g. under what circumstances literal expressions
like ``"foo"`` should be assumed to be of type ``Literal["foo"]`` vs of
type ``str``.

In general, type checkers are expected to infer ``Literal[…]``
conservatively and only in contexts where a ``Literal[…]`` type is
explicitly requested. See the following subsections for examples of what
this looks like.

Variable assignment
'''''''''''''''''''

When assigning a literal expression to an unannotated variable, the
inferred type of the variable should be the original base type, not a
``Literal[…]`` type. For example, consider the following snippet of
code::

   foo = "hello"
   reveal_type(foo)   # Revealed type is 'str'

We want to avoid breaking the semantics of any existing code, so the
inferred type of ``foo`` should be ``str``, **not**
``Literal["hello"]``.

If the user wants ``foo`` to have a literal type, they must either
explicitly add an annotation::

   foo: Literal["hello"] = "hello"
   reveal_types(foo)   # Revealed type is 'Literal["hello"]'

Or alternatively, use the ``Final`` qualifier::

   foo: Final = "hello"
   reveal_types(foo)   # Revealed type is 'Final[Literal["hello"]]'

The ``Final`` qualifier will automatically infer a ``Literal`` type in
an assignment if the LHS is a literal expression, or an expression of
type ``Literal[…]``.

**TODO:** Link to the PEP draft for the ``Final`` qualifier once it's ready.

**Note 1:** A potential third way of declaring a Literal might be to 
try using ``Literal`` as a qualifier::

   foo: Literal = "hello"   # Illegal!

Although this looks reasonable, we feel type checkers should *reject*
constructs like these: while ``Final`` and ``ClassVar`` are *qualifiers*
and so infer their parameters, ``Literal`` is a *type*.

**Note 2:** It may in some cases be possible to use the overall context
of the current scope to determine whether some variable should have a
Literal type or not. For example, in the following function, ``foo`` is
only ever used as an input to a function that expects ``Literal["blah"]``
which means it’s theoretically possible to infer that foo has type
``Literal["blah"]``::

   def expects_blah(x: Literal["blah"]) -> None: ...

   def test() -> None:
       foo = "blah"
       expects_blah(foo)

This PEP proposes that type checkers are **not** expected to handle these
cases: it is ok to infer that ``foo`` has type ``str``.

However, it's an open question whether type checkers are permitted to *try*
handling these more complex cases on a best-effort basis. That is, are
type checkers *obligated* to infer that ``foo`` has type ``str``?

Type inference inside calls
'''''''''''''''''''''''''''

When a literal is used inside of some function call, it will be inferred
as either the original type or the Literal type based on context. For
example, the following code snippet should be legal::

   def expects_str(x: str) -> None: ...
   def expects_literal(x: Literal["foo"]) -> None: ...

   # Legal: "foo" is inferred to be of type 'str'
   expects_str("foo")

   # Legal: "foo" is inferred to be of type 'Literal["foo"]'
   expects_literal("foo")

However, other expressions in general will not automatically be inferred
to be literals. For example::

   def expects_literal(x: Literal["foo"]) -> None: ...

   def runner(my_str: str) -> None:
       # ILLEGAL: str is not a subclass of Literal["foo"]
       expects_literal(my_str)

**Note:** If the user wants their API to support accepting both literals
*and* the original type — perhaps for legacy purposes — they should
implement a fallback overload. See the section below on
`Interactions with overloads`_ for more details.

Miscellaneous interactions
--------------------------

This section of the doc discusses how literal types ought to interact
with other aspects of the PEP 484 type system.

Intelligent indexing of structured data: Interactions with TypedDict, Tuple, NamedTuples, and getattr
'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

The type checker should support "intelligently indexing" into structured
types like TypedDicts, NamedTuple, and classes when using string and int
literal keys. This list is non-exhaustive — there may be other examples
of structured types not included in this list.

For example, if you try indexing into a TypedDict using a string
Literal, the type checker should return the correct value type if the
key is a member of the TypedDict (and return an error if it isn’t)::

   Foo = TypedDict('Foo', {
       'key1': int,
       'key2': str,
       'key3': List[bool],
   })

   a: Final = "key1"
   b: Final = "some other string"

   f: Foo
   reveal_type(f[a])  # Revealed type is 'int'
   f[b]               # Error: 'Foo' does not contain a key named 'some other string'

We require similar behavior when indexing into a tuple or named tuple::

   a: Final = 0
   b: Final = 5

   some_tuple: Tuple[int, str, List[bool]] = (3, "abc", [True, False])
   reveal_type(some_tuple[a])   # Revealed type is 'int'
   some_tuple[b]                # Error: 5 is not a valid index into the tuple

...and when using functions like getattr::

   class Test:
       def __init__(self, param: int) -> None:
           self.myfield = param
       
       def mymethod(self, val: int) -> str: ...
       
   a: Literal = "myfield"
   b: Literal = "mymethod"
   c: Literal = "blah"

   t = Test()
   reveal_type(getattr(t, a))  # Revealed type is 'int'
   reveal_type(getattr(t, b))  # Revealed type is 'Callable[[int], str]'
   getattr(t, c)               # Error: 'Test' does not have attribute named 'blah'

These interactions will most likely need to be added to type checkers on
an ad-hoc basis: e.g. we special-case TypedDicts and NamedTuples,
special-case functions like ``getattr``...

One potential alternative solution would be to implement something
similar to TypeScript’s `index types <typescript-index-types_>`_
and ``keyof`` operator, which lets you encode the idea that some key
(e.g. a literal string) is a member of some object.

We currently do not plan on adding a similar concept to Python. Python
has many different kinds of structured data beyond just objects
(classes, objects, TypedDict, tuples, NamedTuples…) and it’s unclear
what the ramifications of attempting to unify all these different
concepts using this idea might be. This idea (or a similar one) may
potentially be revisited in the future, but not as a part of this PEP.

Interactions with overloads
'''''''''''''''''''''''''''

Literal types and overloads should not need to interact in any
particularly special way: the existing rule for how we handle subtypes
and unions ought to work fine.

However, one important use case we must make sure will work is the
ability to specify a *fallback* when the user is not using literal
types. For example, consider the ``open`` function from before::

   # Note: this is an over-simplification of the true type signature.
   _PathType = Union[str, bytes, int]

   @overload
   def open(path: _PathType, 
            mode: Literal["r", "w", "a", "x", "r+", "w+", "a+", "x+"],
            ) -> IO[Text]: ...
   @overload
   def open(path: _PathType, 
            mode: Literal["rb", "wb", "ab", "xb", "r+b", "w+b", "a+b", "x+b"],
            ) -> IO[bytes]: ...

   # Fallback overload for when the user isn't using literal types
   @overload
   def open(path: _PathType, mode: str) -> IO[Any]: ...

If we changed the signature of ``open`` in typeshed so it uses just the
first two overloads, we could potentially end up breaking some clients
who are not passing in a literal string in as a first argument --
e.g. clients who do something like this::

   mode: str = pick_file_mode(...)
   with open(path, mode) as f:
       # f should continue to be of type IO[Any] here

A little more broadly: we propose adding a policy to typeshed that
mandates that whenever we add literal types to some existing API, we also
include a fallback overload to let clients who happen to not be using
literal types continue using the API as they were before. Literal types
should always be added to existing APIs in backwards-compatible ways.

Interactions with generics
''''''''''''''''''''''''''

Types like ``Literal[3]`` are meant to be just plain old subclasses of
``int``. Consequently, you can use types like ``Literal[3]`` anywhere
you could use normal types, such as with generics.

For example, suppose we want to construct a type representing a
2-dimensional Matrix which can be parameterized by two literal ints
representing the number of rows and columns respectively. Such a type
could be built using the existing generics system like so::

   A = TypeVar('A', bound=int)
   B = TypeVar('B', bound=int)
   C = TypeVar('C', bound=int)

   # A simplified definition for Matrix[row, column]
   class Matrix(Generic[A, B]):
       def __init__(self, elements: List[List[int]]) -> None: ...
       def __add__(self, other: Matrix[A, B]) -> Matrix[A, B]: ...
       def __matmul__(self, other: Matrix[B, C]) -> Matrix[A, C]: ...
       def transpose(self) -> Matrix[B, A]: ...
       
   Foo: Matrix[Literal[2], Literal[3]] = Matrix(...)
   Bar: Matrix[Literal[3], Literal[7]] = Matrix(...)

   reveal_type(Foo @ Bar)  # Revealed type is Matrix[Literal[2], Literal[7]]
   Bar @ Foo               # Error, Foo doesn't match expected type Matrix[Literal[7], Literal[int]]

This class definition is not perfect: it would not prohibit users from
constructing less precise types like ``Matrix[int, int]`` due to the
typevar bound, for example.

We considered several different proposals for addressing this gap, but
ultimately decided to reject them and defer the problem of integer
generics to a later date. See the `Rejected or out-of-scope ideas`_
section below.

Interactions with asserts and other checks
''''''''''''''''''''''''''''''''''''''''''

Type checkers should, at the bare minimum, narrow the type of variables
when they are compared directly against other literal types. For
example::

   def foo(x: str) -> None:
       if x == "foo":
           # Type checker should narrow 'x' to "foo" here
           expects_foo(x)
       
       # Similarly, type checker should narrow 'x' to "bar" here
       assert x == "bar"
       expects_bar(x)

Type checkers may optionally perform additional analysis and narrowing
checks if they so wish.

**Note:** The exact details of this section may be subject to change.

Interactions with Final types
'''''''''''''''''''''''''''''

The interactions between final and literal types were previously
mentioned above, but just to reiterate: if a variable is annotated as
being ``Final``, it should also have an inferred type of ``Literal`` if
the RHS is a literal expression. For example::

   root_id: Final = 1

   # Revealed type should be 'Final[Literal[1]]' or something similar
   reveal_type(root_id)

   # The types of 'root_id' and 'root_id_2' should be identical
   root_id_2: Final[Literal[1]] = 1

**TODO:** Cross-link to draft PEP for 'Final' once it's ready

Rejected or out-of-scope ideas
==============================

This section of the doc outlines some potential features that are
explicitly out-of-scope.

True dependent types/integer generics
-------------------------------------

This proposal is essentially describing adding a very stripped down and
simplified dependent type system to the PEP 484 ecosystem. In contrast,
a full-fledged dependent type system would let users predicate types
based on their values in arbitrary ways. For example, if we had
full-fledged dependent types, it would be possible to write type
signatures like the below::

   # A vector has length 'n', containing elements of type 'T'
   class Vector(Generic[N, T]): ...

   # The type checker will statically verify our function genuinely does 
   # construct a vector that is equal in length to "len(vec1) + len(vec2)"
   # and will throw an error if it does not.
   def vector_concat(vec1: Vector[A, T], vec2: Vector[B, T]) -> Vector[A + B, T]:
       # ...snip...

At the very least, it would be useful to add some form of integer
generics.

There were a few proposals on how this type system might be implemented
— for example, the `Simple dependent types issue <mypy-discussion_>`_ 
on the mypy issue tracker suggested compiling Python to Idris.

Although such a type system could certainly be useful, it’s out-of-scope
for this proposal: it would take a substantial amount of implementation
work, discussion, and research to complete. We also already have a lot
of difficulty as-is trying to exactly keep track of types due to the
``Any`` type and the sheer number of unannotated 3rd party libraries --
attempting to keep track of values as well seems overly optimistic.

That said, it’s entirely possible that PEP 484 will acquire a limited
form of dependent types sometime in the future. Specifically, the mypy
team (and other members of the typing ecosystem) would like to add
better support for numpy and similar modules at some point in the
future. This may potentially involve adding some limited form of
dependant typing, along with other features like variadic generics. This
PEP should be seen as a stepping stone towards that goal.

Adding more concise syntax for literal types
--------------------------------------------

One potential downside of this proposal is that having to explicitly
write ``Literal[…]`` can feel verbose. For example, rather then writing::

   def foobar(arg1: Literal[1], arg2: Literal[True]) -> None:
       pass

...it might be nice to instead write::

   def foobar(arg1: 1, arg2: True) -> None:
       pass

Unfortunately, these abbreviations simply will not work with the
existing implementation of ``typing`` at runtime. For example, if we try
running the following program using Python 3.7::

   from typing import Tuple

   # Supposed to accept tuple containing the literals 1 and 2
   def foo(x: Tuple[1, 2]) -> None:
       pass

...we will get the following exception::

   TypeError: Tuple[t0, t1, …]: each t must be a type. Got 1.

We don’t want users to have to memorize exactly when and where it’s ok
to omit the ``Literal`` keyword, so we require that ``Literal`` is always
present.

Backwards compatibility
=======================

Once this PEP is accepted, the ``Literal`` type will need to be backported for
Python versions that come bundled with older versions of the ``typing`` module.
We plan to do this by adding ``Literal`` to the ``typing_extensions`` 3rd party
module, along with the other backported types.

There should be no backwards compatibility issues apart from this.

Related work
============

This proposal was written based on the discussion that took place in the
following threads:

-  `Check that literals belong to/are excluded from a set of values <typing-discussion_>`_

-  `Simple dependent types <mypy-discussion_>`_

-  `Typing for multi-dimensional arrays <arrays-discussion_>`_

The overall design of this proposal also ended up converging into
something similar to how 
`literal types are handled in TypeScript <typescript-literal-types_>`_.

.. _typing-discussion: https://github.com/python/typing/issues/478

.. _mypy-discussion: https://github.com/python/mypy/issues/3062

.. _arrays-discussion: https://github.com/python/typing/issues/513

.. _typescript-literal-types: https://www.typescriptlang.org/docs/handbook/advanced-types.html#string-literal_types

.. _typescript-index-types: https://www.typescriptlang.org/docs/handbook/advanced-types.html#index-types


Copyright
=========

This document has been placed in the public domain.


..
   Local Variables:
   mode: indented-text
   indent-tabs-mode: nil
   sentence-end-double-space: t
   fill-column: 70
   coding: utf-8
   End:

